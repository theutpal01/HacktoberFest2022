{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous Programming\n",
    "\n",
    "This first example shows a somewhat contrived way of having a task retrieve work from a queue and process that work. A queue in Python is a nice FIFO (first in first out) data structure. It provides methods to put things in a queue and take them out again in the order they were inserted.\n",
    "\n",
    "In this case, the work is to get a number from the queue and have a loop count up to that number. It prints to the console when the loop begins, and again to output the total. This program demonstrates one way for multiple synchronous tasks to process the work in a queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task One running\n",
      "Task One total: 15\n",
      "Task One running\n",
      "Task One total: 10\n",
      "Task One running\n",
      "Task One total: 5\n",
      "Task One running\n",
      "Task One total: 2\n",
      "Task Two nothing to do\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "def task(name, work_queue):\n",
    "    if work_queue.empty():\n",
    "        print(f\"Task {name} nothing to do\")\n",
    "    else:\n",
    "        while not work_queue.empty():\n",
    "            count = work_queue.get()\n",
    "            total = 0\n",
    "            print(f\"Task {name} running\")\n",
    "            for x in range(count):\n",
    "                total += 1\n",
    "            print(f\"Task {name} total: {total}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    This is the main entry point for the program\n",
    "    \"\"\"\n",
    "    # Create the queue of work\n",
    "    work_queue = queue.Queue()\n",
    "\n",
    "    # Put some work in the queue\n",
    "    for work in [15, 10, 5, 2]:\n",
    "        work_queue.put(work)\n",
    "\n",
    "    # Create some synchronous tasks\n",
    "    tasks = [(task, \"One\", work_queue), (task, \"Two\", work_queue)]\n",
    "\n",
    "    # Run the tasks\n",
    "    for t, n, q in tasks:\n",
    "        t(n, q)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s take a look at what each line does:\n",
    "\n",
    "- Line 1 imports the queue module. This is where the program stores work to be done by the tasks. \n",
    "- Lines 3 to 13 define task(). This function pulls work out of work_queue and processes the work until there isn’t any more to do.\n",
    "- Line 15 defines main() to run the program tasks.\n",
    "- Line 20 creates the work_queue. All tasks use this shared resource to retrieve work.\n",
    "- Lines 23 to 24 put work in work_queue. In this case, it’s just a random count of values for the tasks to process.\n",
    "- Line 27 creates a list of task tuples, with the parameter values those tasks will be passed.\n",
    "- Lines 30 to 31 iterate over the list of task tuples, calling each one and passing the previously defined parameter values.\n",
    "- Line 34 calls main() to run the program.\n",
    "\n",
    "The task in this program is just a function accepting a string and a queue as parameters. When executed, it looks for anything in the queue to process. If there is work to do, then it pulls values off the queue, starts a for loop to count up to that value, and outputs the total at the end. It continues getting work off the queue until there is nothing left and it exits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Cooperative Concurrency\n",
    "\n",
    "The next version of the program allows the two tasks to work together. Adding a yield statement means the loop will yield control at the specified point while still maintaining its context. This way, the yielding task can be restarted later.\n",
    "\n",
    "The yield statement turns task() into a generator. A generator function is called just like any other function in Python, but when the yield statement is executed, control is returned to the caller of the function. This is essentially a context switch, as control moves from the generator function to the caller.\n",
    "\n",
    "The interesting part is that control can be given back to the generator function by calling next() on the generator. This is a context switch back to the generator function, which picks up execution with all function variables that were defined before the yield still intact.\n",
    "\n",
    "The while loop in main() takes advantage of this when it calls next(t). This statement restarts the task at the point where it previously yielded. All of this means that you’re in control when the context switch happens: when the yield statement is executed in task().\n",
    "\n",
    "This is a form of cooperative multitasking. The program is yielding control of its current context so that something else can run. In this case, it allows the while loop in main() to run two instances of task() as a generator function. Each instance consumes work from the same queue. This is sort of clever, but it’s also a lot of work to get the same results as the first program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task One running\n",
      "Task Two running\n",
      "Task Two total: 10\n",
      "Task Two running\n",
      "Task One total: 15\n",
      "Task One running\n",
      "Task Two total: 5\n",
      "Task One total: 2\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "def task(name, queue):\n",
    "    while not queue.empty():\n",
    "        count = queue.get()\n",
    "        total = 0\n",
    "        print(f\"Task {name} running\")\n",
    "        for x in range(count):\n",
    "            total += 1\n",
    "            yield\n",
    "        print(f\"Task {name} total: {total}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    This is the main entry point for the program\n",
    "    \"\"\"\n",
    "    # Create the queue of work\n",
    "    work_queue = queue.Queue()\n",
    "\n",
    "    # Put some work in the queue\n",
    "    for work in [15, 10, 5, 2]:\n",
    "        work_queue.put(work)\n",
    "\n",
    "    # Create some tasks\n",
    "    tasks = [task(\"One\", work_queue), task(\"Two\", work_queue)]\n",
    "\n",
    "    # Run the tasks\n",
    "    done = False\n",
    "    while not done:\n",
    "        for t in tasks:\n",
    "            try:\n",
    "                next(t)\n",
    "            except StopIteration:\n",
    "                tasks.remove(t)\n",
    "            if len(tasks) == 0:\n",
    "                done = True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that both Task One and Task Two are running and consuming work from the queue. This is what’s intended, as both tasks are processing work, and each is responsible for two items in the queue. This is interesting, but again, it takes quite a bit of work to achieve these results.\n",
    "\n",
    "The trick here is using the yield statement, which turns task() into a generator and performs a context switch. The program uses this context switch to give control to the while loop in main(), allowing two instances of a task to run cooperatively.\n",
    "\n",
    "Notice how Task Two outputs its total first. This might lead you to think that the tasks are running asynchronously. However, this is still a synchronous program. It’s structured so the two tasks can trade contexts back and forth. The reason why Task Two outputs its total first is that it’s only counting to 10, while Task One is counting to 15. Task Two simply arrives at its total first, so it gets to print its output to the console before Task One."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s what’s happening in the code above:\n",
    "\n",
    "- Lines 3 to 11 define task() as before, but the addition of yield on Line 10 turns the function into a generator. This where the context switch is made and control is handed back to the while loop in main().\n",
    "- Line 25 creates the task list, but in a slightly different manner than you saw in the previous example code. In this case, each task is called with its parameters as its entered in the tasks list variable. This is necessary to get the task() generator function running the first time.\n",
    "- Lines 31 to 36 are the modifications to the while loop in main() that allow task() to run cooperatively. This is where control returns to each instance of task() when it yields, allowing the loop to continue and run another task.\n",
    "- Line 32 gives control back to task(), and continues its execution after the point where yield was called.\n",
    "- Line 36 sets the done variable. The while loop ends when all tasks have been completed and removed from tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooperative Concurrency With Blocking Calls\n",
    "The next version of the program is the same as the last, except for the addition of a time.sleep(delay) in the body of your task loop. This adds a delay based on the value retrieved from the work queue to every iteration of the task loop. The delay simulates the effect of a blocking call occurring in your task.\n",
    "\n",
    "A blocking call is code that stops the CPU from doing anything else for some period of time. In the thought experiments above, if a parent wasn’t able to break away from balancing the checkbook until it was complete, that would be a blocking call.\n",
    "\n",
    "time.sleep(delay) does the same thing in this example, because the CPU can’t do anything else but wait for the delay to expire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting codetiming\n",
      "  Downloading codetiming-1.2.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: codetiming\n",
      "Successfully installed codetiming-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install codetiming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task One running\n",
      "Task One elapsed time: 15.0\n",
      "Task Two running\n",
      "Task Two elapsed time: 10.0\n",
      "Task One running\n",
      "Task One elapsed time: 5.0\n",
      "Task Two running\n",
      "Task Two elapsed time: 2.0\n",
      "\n",
      "Total elapsed time: 32.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import queue\n",
    "from codetiming import Timer\n",
    "\n",
    "def task(name, queue):\n",
    "    timer = Timer(text=f\"Task {name} elapsed time: {{:.1f}}\")\n",
    "    while not queue.empty():\n",
    "        delay = queue.get()\n",
    "        print(f\"Task {name} running\")\n",
    "        timer.start()\n",
    "        time.sleep(delay)\n",
    "        timer.stop()\n",
    "        yield\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    This is the main entry point for the program\n",
    "    \"\"\"\n",
    "    # Create the queue of work\n",
    "    work_queue = queue.Queue()\n",
    "\n",
    "    # Put some work in the queue\n",
    "    for work in [15, 10, 5, 2]:\n",
    "        work_queue.put(work)\n",
    "\n",
    "    tasks = [task(\"One\", work_queue), task(\"Two\", work_queue)]\n",
    "\n",
    "    # Run the tasks\n",
    "    done = False\n",
    "    with Timer(text=\"\\nTotal elapsed time: {:.1f}\"):\n",
    "        while not done:\n",
    "            for t in tasks:\n",
    "                try:\n",
    "                    next(t)\n",
    "                except StopIteration:\n",
    "                    tasks.remove(t)\n",
    "                if len(tasks) == 0:\n",
    "                    done = True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s what’s different in the code above:\n",
    "\n",
    "- Line 1 imports the time module to give the program access to time.sleep().\n",
    "- Line 3 imports the the Timer code from the codetiming module.\n",
    "- Line 6 creates the Timer instance used to measure the time taken for each iteration of the task loop.\n",
    "- Line 10 starts the timer instance\n",
    "- Line 11 changes task() to include a time.sleep(delay) to mimic an IO delay. This replaces the for loop that did the counting in previous example.\n",
    "- Line 12 stops the timer instance and outputs the elapsed time since timer.start() was called.\n",
    "- Line 30 creates a Timer context manager that will output the elapsed time the entire while loop took to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooperative Concurrency With Non-Blocking Calls\n",
    "The next version of the program has been modified quite a bit. It makes use of Python async features using asyncio/await provided in Python 3.\n",
    "\n",
    "The time and queue modules have been replaced with the asyncio package. This gives your program access to asynchronous friendly (non-blocking) sleep and queue functionality. The change to task() defines it as asynchronous with the addition of the async prefix on line 4. This indicates to Python that the function will be asynchronous.\n",
    "\n",
    "The other big change is removing the time.sleep(delay) and yield statements, and replacing them with await asyncio.sleep(delay). This creates a non-blocking delay that will perform a context switch back to the caller main().\n",
    "\n",
    "The while loop inside main() no longer exists. Instead of task_array, there’s a call to await asyncio.gather(...). This tells asyncio two things:\n",
    "\n",
    "Create two tasks based on task() and start running them.\n",
    "Wait for both of these to be completed before moving forward.\n",
    "The last line of the program asyncio.run(main()) runs main(). This creates what’s known as an event loop). It’s this loop that will run main(), which in turn will run the two instances of task().\n",
    "\n",
    "The event loop is at the heart of the Python async system. It runs all the code, including main(). When task code is executing, the CPU is busy doing work. When the await keyword is reached, a context switch occurs, and control passes back to the event loop. The event loop looks at all the tasks waiting for an event (in this case, an asyncio.sleep(delay) timeout) and passes control to a task with an event that’s ready.\n",
    "\n",
    "await asyncio.sleep(delay) is non-blocking in regards to the CPU. Instead of waiting for the delay to timeout, the CPU registers a sleep event on the event loop task queue and performs a context switch by passing control to the event loop. The event loop continuously looks for completed events and passes control back to the task waiting for that event. In this way, the CPU can stay busy if work is available, while the event loop monitors the events that will happen in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: coroutine 'main' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task One running\n",
      "Task Two running\n",
      "Task Two elapsed time: 10.0\n",
      "Task Two running\n",
      "Task One elapsed time: 15.0\n",
      "Task One running\n",
      "Task Two elapsed time: 5.0\n",
      "Task One elapsed time: 2.0\n",
      "\n",
      "Total elapsed time: 17.0\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from codetiming import Timer\n",
    "\n",
    "async def task(name, work_queue):\n",
    "    timer = Timer(text=f\"Task {name} elapsed time: {{:.1f}}\")\n",
    "    while not work_queue.empty():\n",
    "        delay = await work_queue.get()\n",
    "        print(f\"Task {name} running\")\n",
    "        timer.start()\n",
    "        await asyncio.sleep(delay)\n",
    "        timer.stop()\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    This is the main entry point for the program\n",
    "    \"\"\"\n",
    "    # Create the queue of work\n",
    "    work_queue = asyncio.Queue()\n",
    "\n",
    "    # Put some work in the queue\n",
    "    for work in [15, 10, 5, 2]:\n",
    "        await work_queue.put(work)\n",
    "\n",
    "    # Run the tasks\n",
    "    with Timer(text=\"\\nTotal elapsed time: {:.1f}\"):\n",
    "        await asyncio.gather(\n",
    "            asyncio.create_task(task(\"One\", work_queue)),\n",
    "            asyncio.create_task(task(\"Two\", work_queue)),\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Line 1 imports asyncio to gain access to Python async functionality. This replaces the time import.\n",
    "- Line 2 imports the the Timer code from the codetiming module.\n",
    "- Line 4 shows the addition of the async keyword in front of the task() definition. This informs the program that task can run asynchronously.\n",
    "- Line 5 creates the Timer instance used to measure the time taken for each iteration of the task loop.\n",
    "- Line 9 starts the timer instance\n",
    "- Line 10 replaces time.sleep(delay) with the non-blocking asyncio.sleep(delay), which also yields control (or switches contexts) back to the main event loop.\n",
    "- Line 11 stops the timer instance and outputs the elapsed time since timer.start() was called.\n",
    "- Line 18 creates the non-blocking asynchronous work_queue.\n",
    "- Lines 21 to 22 put work into work_queue in an asynchronous manner using the await keyword.\n",
    "- Line 25 creates a Timer context manager that will output the elapsed time the entire while loop took to execute.\n",
    "- Lines 26 to 29 create the two tasks and gather them together, so the program will wait for both tasks to complete.\n",
    "- Line 32 starts the program running asynchronously. It also starts the internal event loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous (Blocking) HTTP Calls\n",
    "The next version of the program is kind of a step forward as well as a step back. The program is doing some actual work with real IO by making HTTP requests to a list of URLs and getting the page contents. However, it’s doing so in a blocking (synchronous) manner.\n",
    "\n",
    "The program has been modified to import the wonderful requests module to make the actual HTTP requests. Also, the queue now contains a list of URLs, rather than numbers. In addition, task() no longer increments a counter. Instead, requests gets the contents of a URL retrieved from the queue, and prints how long it took to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asiso\\anaconda3\\lib\\zipfile.py:774: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  class _Tellable:\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task One getting URL: http://google.com\n",
      "Task One elapsed time: 0.7\n",
      "Task Two getting URL: http://yahoo.com\n",
      "Task Two elapsed time: 3.1\n",
      "Task One getting URL: http://linkedin.com\n",
      "Task One elapsed time: 3.9\n",
      "Task Two getting URL: http://apple.com\n",
      "Task Two elapsed time: 1.0\n",
      "Task One getting URL: http://microsoft.com\n",
      "Task One elapsed time: 1.2\n",
      "Task Two getting URL: http://facebook.com\n",
      "Task Two elapsed time: 6.4\n",
      "\n",
      "Total elapsed time: 16.4\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import requests\n",
    "from codetiming import Timer\n",
    "\n",
    "def task(name, work_queue):\n",
    "    timer = Timer(text=f\"Task {name} elapsed time: {{:.1f}}\")\n",
    "    with requests.Session() as session:\n",
    "        while not work_queue.empty():\n",
    "            url = work_queue.get()\n",
    "            print(f\"Task {name} getting URL: {url}\")\n",
    "            timer.start()\n",
    "            session.get(url)\n",
    "            timer.stop()\n",
    "            yield\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    This is the main entry point for the program\n",
    "    \"\"\"\n",
    "    # Create the queue of work\n",
    "    work_queue = queue.Queue()\n",
    "\n",
    "    # Put some work in the queue\n",
    "    for url in [\n",
    "        \"http://google.com\",\n",
    "        \"http://yahoo.com\",\n",
    "        \"http://linkedin.com\",\n",
    "        \"http://apple.com\",\n",
    "        \"http://microsoft.com\",\n",
    "        \"http://facebook.com\",\n",
    "    ]:\n",
    "        work_queue.put(url)\n",
    "\n",
    "    tasks = [task(\"One\", work_queue), task(\"Two\", work_queue)]\n",
    "\n",
    "    # Run the tasks\n",
    "    done = False\n",
    "    with Timer(text=\"\\nTotal elapsed time: {:.1f}\"):\n",
    "        while not done:\n",
    "            for t in tasks:\n",
    "                try:\n",
    "                    next(t)\n",
    "                except StopIteration:\n",
    "                    tasks.remove(t)\n",
    "                if len(tasks) == 0:\n",
    "                    done = True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Line 2 imports requests, which provides a convenient way to make HTTP calls.\n",
    "- Line 3 imports the the Timer code from the codetiming module.\n",
    "- Line 6 creates the Timer instance used to measure the time taken for each iteration of the task loop.\n",
    "- Line 11 starts the timer instance\n",
    "- Line 12 introduces a delay, similar to example_3.py. However, this time it calls session.get(url), which returns the contents of the URL retrieved from work_queue.\n",
    "- Line 13 stops the timer instance and outputs the elapsed time since timer.start() was called.\n",
    "- Lines 23 to 32 put the list of URLs into work_queue.\n",
    "- Line 39 creates a Timer context manager that will output the elapsed time the entire while loop took to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in earlier versions of the program, yield turns task() into a generator. It also performs a context switch that lets the other task instance run.\n",
    "\n",
    "Each task gets a URL from the work queue, retrieves the contents of the page, and reports how long it took to get that content.\n",
    "\n",
    "As before, yield allows both your tasks to run cooperatively. However, since this program is running synchronously, each session.get() call blocks the CPU until the page is retrieved. Note the total time it took to run the entire program at the end. This will be meaningful for the next example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous (Non-Blocking) HTTP Calls\n",
    "This version of the program modifies the previous one to use Python async features. It also imports the aiohttp module, which is a library to make HTTP requests in an asynchronous fashion using asyncio.\n",
    "\n",
    "The tasks here have been modified to remove the yield call since the code to make the HTTP GET call is no longer blocking. It also performs a context switch back to the event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.6.2-py3-none-any.whl (441 kB)\n",
      "Collecting multidict<5.0,>=4.5\n",
      "  Downloading multidict-4.7.6-cp38-cp38-win_amd64.whl (48 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.5.1-cp38-cp38-win_amd64.whl (128 kB)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in c:\\users\\asiso\\anaconda3\\lib\\site-packages (from aiohttp) (3.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asiso\\anaconda3\\lib\\site-packages (from aiohttp) (19.3.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\asiso\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp) (2.10)\n",
      "Installing collected packages: multidict, yarl, async-timeout, aiohttp\n",
      "Successfully installed aiohttp-3.6.2 async-timeout-3.0.1 multidict-4.7.6 yarl-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task One getting URL: http://google.com\n",
      "Task Two getting URL: http://yahoo.com\n",
      "Task One elapsed time: 0.9\n",
      "Task One getting URL: http://linkedin.com\n",
      "Task One elapsed time: 4.6\n",
      "Task One getting URL: http://apple.com\n",
      "Task Two elapsed time: 6.1\n",
      "Task Two getting URL: http://microsoft.com\n",
      "Task One elapsed time: 1.1\n",
      "Task One getting URL: http://facebook.com\n",
      "Task Two elapsed time: 2.4\n",
      "Task One elapsed time: 3.2\n",
      "\n",
      "Total elapsed time: 9.7\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from codetiming import Timer\n",
    "\n",
    "async def task(name, work_queue):\n",
    "    timer = Timer(text=f\"Task {name} elapsed time: {{:.1f}}\")\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        while not work_queue.empty():\n",
    "            url = await work_queue.get()\n",
    "            print(f\"Task {name} getting URL: {url}\")\n",
    "            timer.start()\n",
    "            async with session.get(url) as response:\n",
    "                await response.text()\n",
    "            timer.stop()\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    This is the main entry point for the program\n",
    "    \"\"\"\n",
    "    # Create the queue of work\n",
    "    work_queue = asyncio.Queue()\n",
    "\n",
    "    # Put some work in the queue\n",
    "    for url in [\n",
    "        \"http://google.com\",\n",
    "        \"http://yahoo.com\",\n",
    "        \"http://linkedin.com\",\n",
    "        \"http://apple.com\",\n",
    "        \"http://microsoft.com\",\n",
    "        \"http://facebook.com\",\n",
    "    ]:\n",
    "        await work_queue.put(url)\n",
    "\n",
    "    # Run the tasks\n",
    "    with Timer(text=\"\\nTotal elapsed time: {:.1f}\"):\n",
    "        await asyncio.gather(\n",
    "            asyncio.create_task(task(\"One\", work_queue)),\n",
    "            asyncio.create_task(task(\"Two\", work_queue)),\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Line 2 imports the aiohttp library, which provides an asynchronous way to make HTTP calls.\n",
    "- Line 3 imports the the Timer code from the codetiming module.\n",
    "- Line 5 marks task() as an asynchronous function.\n",
    "- Line 6 creates the Timer instance used to measure the time taken for each iteration of the task loop.\n",
    "- Line 7 creates an aiohttp session context manager.\n",
    "- Line 8 creates an aiohttp response context manager. It also makes an HTTP GET call to the URL taken from work_queue.\n",
    "- Line 11 starts the timer instance\n",
    "- Line 12 uses the session to get the text retrieved from the URL asynchronously.\n",
    "- Line 13 stops the timer instance and outputs the elapsed time since timer.start() was called.\n",
    "- Line 39 creates a Timer context manager that will output the elapsed time the entire while loop took to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the total elapsed time, as well as the individual times to get the contents of each URL. You’ll see that the duration is about half the cumulative time of all the HTTP GET calls. This is because the HTTP GET calls are running asynchronously. In other words, you’re effectively taking better advantage of the CPU by allowing it to make multiple requests at once.\n",
    "\n",
    "Because the CPU is so fast, this example could likely create as many tasks as there are URLs. In this case, the program’s run time would be that of the single slowest URL retrieval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
